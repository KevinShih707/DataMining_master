{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, attribute, threshold):\n",
    "        self.attr = attribute\n",
    "        self.thres = threshold\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.leaf = False\n",
    "        self.predict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First select the threshold of the attribute to split set of test data on\n",
    "# The threshold chosen splits the test data such that information gain is maximized\n",
    "def select_threshold(df, attribute, predict_attr):\n",
    "    # Convert dataframe column to a list and round each value\n",
    "    values = df[attribute].tolist()\n",
    "    values = [ float(x) for x in values]\n",
    "    # Remove duplicate values by converting the list to a set, then sort the set\n",
    "    values = set(values)\n",
    "    values = list(values)\n",
    "    values.sort()\n",
    "    max_ig = float(\"-inf\")\n",
    "    thres_val = 0\n",
    "    # try all threshold values that are half-way between successive values in this sorted list\n",
    "    for i in range(0, len(values) - 1):\n",
    "        thres = (values[i] + values[i+1])/2\n",
    "        ig = info_gain(df, attribute, predict_attr, thres)\n",
    "        if ig > max_ig:\n",
    "            max_ig = ig\n",
    "            thres_val = thres\n",
    "    # Return the threshold value that maximizes information gained\n",
    "    return thres_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate info content (entropy) of the test data\n",
    "def info_entropy(df, predict_attr):\n",
    "    # Dataframe and number of positive/negatives examples in the data\n",
    "    p_df = df[df[predict_attr] == 1]\n",
    "    n_df = df[df[predict_attr] == 0]\n",
    "    p = float(p_df.shape[0])\n",
    "    n = float(n_df.shape[0])\n",
    "    # Calculate entropy\n",
    "    if p  == 0 or n == 0:\n",
    "        I = 0\n",
    "    else:\n",
    "        I = ((-1*p)/(p + n))*math.log(p/(p+n), 2) + ((-1*n)/(p + n))*math.log(n/(p+n), 2)\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the weighted average of the entropy after an attribute test\n",
    "def remainder(df, df_subsets, predict_attr):\n",
    "    # number of test data\n",
    "    num_data = df.shape[0]\n",
    "    remainder = float(0)\n",
    "    for df_sub in df_subsets:\n",
    "        if df_sub.shape[0] > 1:\n",
    "            remainder += float(df_sub.shape[0]/num_data)*info_entropy(df_sub, predict_attr)\n",
    "    return remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the information gain from the attribute test based on a given threshold\n",
    "# Note: thresholds can change for the same attribute over time\n",
    "def info_gain(df, attribute, predict_attr, threshold):\n",
    "    sub_1 = df[df[attribute] < threshold]\n",
    "    sub_2 = df[df[attribute] > threshold]\n",
    "    # Determine information content, and subract remainder of attributes from it\n",
    "    ig = info_entropy(df, predict_attr) - remainder(df, [sub_1, sub_2], predict_attr)\n",
    "    return ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the number of positive and negative data\n",
    "def num_class(df, predict_attr):\n",
    "    p_df = df[df[predict_attr] == 1]\n",
    "    n_df = df[df[predict_attr] == 0]\n",
    "    return p_df.shape[0], n_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chooses the attribute and its threshold with the highest info gain\n",
    "# from the set of attributes\n",
    "def choose_attr(df, attributes, predict_attr):\n",
    "    max_info_gain = float(\"-inf\")\n",
    "    best_attr = None\n",
    "    threshold = 0\n",
    "    # Test each attribute (note attributes maybe be chosen more than once)\n",
    "    for attr in attributes:\n",
    "        thres = select_threshold(df, attr, predict_attr)\n",
    "        ig = info_gain(df, attr, predict_attr, thres)\n",
    "        if ig > max_info_gain:\n",
    "            max_info_gain = ig\n",
    "            best_attr = attr\n",
    "            threshold = thres\n",
    "    return best_attr, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds the Decision Tree based on training data, attributes to train on,\n",
    "# and a prediction attribute\n",
    "def build_tree(df, cols, predict_attr):\n",
    "    # Get the number of positive and negative examples in the training data\n",
    "    p, n = num_class(df, predict_attr)\n",
    "    # If train data has all positive or all negative values\n",
    "    # then we have reached the end of our tree\n",
    "    if p == 0 or n == 0:\n",
    "        # Create a leaf node indicating it's prediction\n",
    "        leaf = Node(None,None)\n",
    "        leaf.leaf = True\n",
    "        if p > n:\n",
    "            leaf.predict = 1\n",
    "        else:\n",
    "            leaf.predict = 0\n",
    "        return leaf\n",
    "    else:\n",
    "        # Determine attribute and its threshold value with the highest\n",
    "        # information gain\n",
    "        best_attr, threshold = choose_attr(df, cols, predict_attr)\n",
    "        # Create internal tree node based on attribute and it's threshold\n",
    "        tree = Node(best_attr, threshold)\n",
    "        sub_1 = df[df[best_attr] < threshold]\n",
    "        sub_2 = df[df[best_attr] > threshold]\n",
    "        # Recursively build left and right subtree\n",
    "        tree.left = build_tree(sub_1, cols, predict_attr)\n",
    "        tree.right = build_tree(sub_2, cols, predict_attr)\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a instance of a training data, make a prediction of healthy or colic\n",
    "# based on the Decision Tree\n",
    "# Assumes all data has been cleaned (i.e. no NULL data)\n",
    "def predict(node, row_df):\n",
    "    # If we are at a leaf node, return the prediction of the leaf node\n",
    "    if node.leaf:\n",
    "        return node.predict\n",
    "    # Traverse left or right subtree based on instance's data\n",
    "    if row_df[node.attr] <= node.thres:\n",
    "        return predict(node.left, row_df)\n",
    "    elif row_df[node.attr] > node.thres:\n",
    "        return predict(node.right, row_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a set of data, make a prediction for each instance using the Decision Tree\n",
    "def test_predictions(root, df):\n",
    "    num_data = df.shape[0]\n",
    "    num_correct = 0\n",
    "    for index,row in df.iterrows():\n",
    "        prediction = predict(root, row)\n",
    "        if prediction == row['Outcome']:\n",
    "            num_correct += 1\n",
    "    return round(num_correct/num_data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the tree level starting at given level\n",
    "def print_tree(root, level):\n",
    "    #print(counter*\" \", end=\"\")\n",
    "    if root.leaf:\n",
    "        print(root.predict)\n",
    "    else:\n",
    "        print(root.attr)\n",
    "    if root.left:\n",
    "        print_tree(root.left, level + 1)\n",
    "    if root.right:\n",
    "        print_tree(root.right, level + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleans the input data, removes 'Diagnosis' column and adds 'Outcome' column\n",
    "# where 0 means healthy and 1 means colic\n",
    "def clean(csv_file_name):\n",
    "    df = pd.read_csv(csv_file_name, header=None)\n",
    "    df.columns = ['studytime', 'failures', 'grade', 'address', 'Pstatus', 'Medu', 'Fedu', \n",
    "             'traveltime', 'schoolsup', 'famsup', 'paid', 'activities', 'higher', \n",
    "             'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'health',\n",
    "             'adsences','good_student']\n",
    "    # Create new column 'Outcome' that assigns healthy horses a value of 0 (negative case) and\n",
    "    # horses with colic a value of 1 (positive case), this makes creating our decision tree easier\n",
    "    df['Outcome'] = 0\n",
    "    df.loc[df['good_student'] == 'colic.', 'Outcome'] = 1\n",
    "    df.drop(['good_student'], axis=1 )\n",
    "    cols = df.columns\n",
    "    df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "    print(df.head(5))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   studytime  failures  grade  address  Pstatus  Medu  Fedu  traveltime  \\\n",
      "0          2         0    NaN      NaN      NaN     4     4           2   \n",
      "1          2         0    NaN      NaN      NaN     1     1           1   \n",
      "2          2         0    NaN      NaN      NaN     1     1           1   \n",
      "3          3         0    NaN      NaN      NaN     4     2           1   \n",
      "4          2         0    NaN      NaN      NaN     3     3           1   \n",
      "\n",
      "   schoolsup  famsup  ...  internet  romantic  famrel  freetime  goout  Dalc  \\\n",
      "0        NaN     NaN  ...       NaN       NaN       4         3      4     1   \n",
      "1        NaN     NaN  ...       NaN       NaN       5         3      3     1   \n",
      "2        NaN     NaN  ...       NaN       NaN       4         3      2     2   \n",
      "3        NaN     NaN  ...       NaN       NaN       3         2      2     1   \n",
      "4        NaN     NaN  ...       NaN       NaN       4         3      2     1   \n",
      "\n",
      "   health  adsences  good_student  Outcome  \n",
      "0       3         4             0        0  \n",
      "1       3         2             0        0  \n",
      "2       3         6             1        0  \n",
      "3       5         0             1        0  \n",
      "4       5         0             1        0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "studytime\n",
      "0\n",
      "failures\n",
      "failures\n",
      "0\n",
      "0\n",
      "0\n",
      "Accuracy of test data\n",
      "   studytime  failures  grade  address  Pstatus  Medu  Fedu  traveltime  \\\n",
      "0          2         0    NaN      NaN      NaN     4     2           1   \n",
      "1          2         0    NaN      NaN      NaN     4     4           1   \n",
      "2          1         0    NaN      NaN      NaN     1     1           4   \n",
      "3          3         0    NaN      NaN      NaN     4     4           2   \n",
      "4          2         0    NaN      NaN      NaN     1     1           1   \n",
      "\n",
      "   schoolsup  famsup  ...  internet  romantic  famrel  freetime  goout  Dalc  \\\n",
      "0        NaN     NaN  ...       NaN       NaN       4         2      3     1   \n",
      "1        NaN     NaN  ...       NaN       NaN       2         4      4     2   \n",
      "2        NaN     NaN  ...       NaN       NaN       5         5      5     5   \n",
      "3        NaN     NaN  ...       NaN       NaN       2         4      3     1   \n",
      "4        NaN     NaN  ...       NaN       NaN       4         3      2     2   \n",
      "\n",
      "   health  adsences  good_student  Outcome  \n",
      "0       5         2             1        0  \n",
      "1       4         0             1        0  \n",
      "2       5         0             0        0  \n",
      "3       5         4             1        0  \n",
      "4       4         2             1        0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # An example use of 'build_tree' and 'predict'\n",
    "    df_train = clean('data/student_all_train.csv')\n",
    "    attributes =  ['studytime', 'failures']\n",
    "    root = build_tree(df_train, attributes, 'good_student')\n",
    "    print_tree(root,1)\n",
    "    print(\"Accuracy of test data\")\n",
    "    df_test = clean('data/student_all_test.csv')\n",
    "    print(str(test_predictions(root, df_test)*100.0) + '%')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
